{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caeed49d-94aa-4797-ae6f-431292804739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "#Sleeper API calls:\n",
    "\n",
    "# Player Data:\n",
    "player_data = \"https://api.sleeper.app/v1/players/nfl\"\n",
    "\n",
    "# League Roster Data:\n",
    "monstars_league_data = \"https://api.sleeper.app/v1/league/1109200666398048256/rosters\"\n",
    "    #LeagueID#: 1109200666398048256\n",
    "dynasty_warriors_league_data = \"https://api.sleeper.app/v1/league/1076723048801296384/rosters\"\n",
    "    #LeagueID#:1076723048801296384\n",
    "\n",
    "# League Users:\n",
    "monstars_users = \"https://api.sleeper.app/v1/league/1109200666398048256/users\"\n",
    "dynasty_warriors_users = \"https://api.sleeper.app/v1/league/1076723048801296384/users\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5c3d6ff-330a-457a-ab41-0fce1471b0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! API call worked.\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(player_data)  # Replace with appropriate API URL\n",
    "if response.status_code == 200:\n",
    "    print(\"Success! API call worked.\")\n",
    "else:\n",
    "    print(f\"Error: Status code {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2316cce8-27aa-48be-a490-12a46733d275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! API call worked.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(monstars_league_data)  # Replace with appropriate API URL\n",
    "if response.status_code == 200:\n",
    "    print(\"Success! API call worked.\")\n",
    "else:\n",
    "    print(f\"Error: Status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baa2c8a6-97b6-4f96-bdc2-444593216f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! API call worked.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(dynasty_warriors_league_data)  # Replace with appropriate API URL\n",
    "if response.status_code == 200:\n",
    "    print(\"Success! API call worked.\")\n",
    "else:\n",
    "    print(f\"Error: Status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7dc4c62-c781-45de-98a6-03e64a28b99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! API call worked.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(monstars_users)  # Replace with appropriate API URL\n",
    "if response.status_code == 200:\n",
    "    print(\"Success! API call worked.\")\n",
    "else:\n",
    "    print(f\"Error: Status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ef93dec-818a-42c2-aec3-533b98c82a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! API call worked.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(dynasty_warriors_users)  # Replace with appropriate API URL\n",
    "if response.status_code == 200:\n",
    "    print(\"Success! API call worked.\")\n",
    "else:\n",
    "    print(f\"Error: Status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d191bb82-239f-43b8-81ff-3e3bf9ddd204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 2015...\n",
      "Fetching data for 2016...\n",
      "Fetching data for 2017...\n",
      "Fetching data for 2018...\n",
      "Fetching data for 2019...\n",
      "Fetching data for 2020...\n",
      "Fetching data for 2021...\n",
      "Fetching data for 2022...\n",
      "Fetching data for 2023...\n",
      "Fetching data for 2024...\n",
      "Data collection complete!\n"
     ]
    }
   ],
   "source": [
    "#College Football Data API.\n",
    "    # Games and player data from 2015-2025\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Add a delay (e.g., 2 seconds) between requests\n",
    "time.sleep(45)  # Adjust the delay based on the API's rate limit guidelines\n",
    "\n",
    "\n",
    "# API base URL\n",
    "players_games_data = \"https://api.collegefootballdata.com/stats/player/season\"  # Adjust to match endpoint\n",
    "\n",
    "# Years to collect data for\n",
    "years = range(2015, 2025)  # Example: 2020 through 2024\n",
    "\n",
    "# Authorization Header (replace with your actual API key)\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer vxEyQMi1J8NLv2HGes5VoTkMZrecMCkXL+8ijS6mBWeobZPm61+nvIwwaXfwxU4N\"\n",
    "}\n",
    "\n",
    "# List to store data for all years\n",
    "all_data = []\n",
    "\n",
    "# Loop through each year and make the API call\n",
    "for year in years:\n",
    "    print(f\"Fetching data for {year}...\")\n",
    "    params = {\n",
    "        \"year\": year,\n",
    "        \"classification\": \"fbs\",  # Optional: Include all teams in FBS\n",
    "        \"seasonType\": \"regular\",  # Regular season data\n",
    "    }\n",
    "\n",
    "    response = requests.get(players_games_data, headers=headers, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()  # Parse JSON response\n",
    "        all_data.extend(data)  # Add data to the list\n",
    "    else:\n",
    "        print(f\"Error fetching data for {year}: {response.status_code}\")\n",
    "        print(response.text)\n",
    "\n",
    "# Convert the aggregated data to a DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Save to a CSV file for future use\n",
    "df.to_csv(\"college_football_player_data.csv\", index=False)\n",
    "\n",
    "print(\"Data collection complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74aa03e9-99f4-48e0-bff4-ab1c076efa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 2015, Conference: SEC...\n",
      "Fetching data for 2015, Conference: ACC...\n",
      "Fetching data for 2015, Conference: Big Ten...\n",
      "Fetching data for 2015, Conference: Big 12...\n",
      "Fetching data for 2015, Conference: Pac-12...\n",
      "Fetching data for 2015, Conference: AAC...\n",
      "Fetching data for 2015, Conference: MWC...\n",
      "Fetching data for 2015, Conference: C-USA...\n",
      "Fetching data for 2015, Conference: MAC...\n",
      "Fetching data for 2015, Conference: Sun Belt...\n",
      "Fetching data for 2016, Conference: SEC...\n",
      "Fetching data for 2016, Conference: ACC...\n",
      "Fetching data for 2016, Conference: Big Ten...\n",
      "Fetching data for 2016, Conference: Big 12...\n",
      "Fetching data for 2016, Conference: Pac-12...\n",
      "Fetching data for 2016, Conference: AAC...\n",
      "Fetching data for 2016, Conference: MWC...\n",
      "Fetching data for 2016, Conference: C-USA...\n",
      "Fetching data for 2016, Conference: MAC...\n",
      "Fetching data for 2016, Conference: Sun Belt...\n",
      "Fetching data for 2017, Conference: SEC...\n",
      "Fetching data for 2017, Conference: ACC...\n",
      "Fetching data for 2017, Conference: Big Ten...\n",
      "Fetching data for 2017, Conference: Big 12...\n",
      "Fetching data for 2017, Conference: Pac-12...\n",
      "Fetching data for 2017, Conference: AAC...\n",
      "Fetching data for 2017, Conference: MWC...\n",
      "Fetching data for 2017, Conference: C-USA...\n",
      "Fetching data for 2017, Conference: MAC...\n",
      "Fetching data for 2017, Conference: Sun Belt...\n",
      "Fetching data for 2018, Conference: SEC...\n",
      "Fetching data for 2018, Conference: ACC...\n",
      "Fetching data for 2018, Conference: Big Ten...\n",
      "Fetching data for 2018, Conference: Big 12...\n",
      "Fetching data for 2018, Conference: Pac-12...\n",
      "Fetching data for 2018, Conference: AAC...\n",
      "Fetching data for 2018, Conference: MWC...\n",
      "Fetching data for 2018, Conference: C-USA...\n",
      "Fetching data for 2018, Conference: MAC...\n",
      "Fetching data for 2018, Conference: Sun Belt...\n",
      "Fetching data for 2019, Conference: SEC...\n",
      "Fetching data for 2019, Conference: ACC...\n",
      "Fetching data for 2019, Conference: Big Ten...\n",
      "Fetching data for 2019, Conference: Big 12...\n",
      "Fetching data for 2019, Conference: Pac-12...\n",
      "Fetching data for 2019, Conference: AAC...\n",
      "Fetching data for 2019, Conference: MWC...\n",
      "Fetching data for 2019, Conference: C-USA...\n",
      "Fetching data for 2019, Conference: MAC...\n",
      "Fetching data for 2019, Conference: Sun Belt...\n",
      "Fetching data for 2020, Conference: SEC...\n",
      "Fetching data for 2020, Conference: ACC...\n",
      "Fetching data for 2020, Conference: Big Ten...\n",
      "Fetching data for 2020, Conference: Big 12...\n",
      "Fetching data for 2020, Conference: Pac-12...\n",
      "Fetching data for 2020, Conference: AAC...\n",
      "Fetching data for 2020, Conference: MWC...\n",
      "Fetching data for 2020, Conference: C-USA...\n",
      "Fetching data for 2020, Conference: MAC...\n",
      "Fetching data for 2020, Conference: Sun Belt...\n",
      "Fetching data for 2021, Conference: SEC...\n",
      "Fetching data for 2021, Conference: ACC...\n",
      "Fetching data for 2021, Conference: Big Ten...\n",
      "Fetching data for 2021, Conference: Big 12...\n",
      "Fetching data for 2021, Conference: Pac-12...\n",
      "Fetching data for 2021, Conference: AAC...\n",
      "Fetching data for 2021, Conference: MWC...\n",
      "Fetching data for 2021, Conference: C-USA...\n",
      "Fetching data for 2021, Conference: MAC...\n",
      "Fetching data for 2021, Conference: Sun Belt...\n",
      "Fetching data for 2022, Conference: SEC...\n",
      "Fetching data for 2022, Conference: ACC...\n",
      "Fetching data for 2022, Conference: Big Ten...\n",
      "Fetching data for 2022, Conference: Big 12...\n",
      "Fetching data for 2022, Conference: Pac-12...\n",
      "Fetching data for 2022, Conference: AAC...\n",
      "Fetching data for 2022, Conference: MWC...\n",
      "Fetching data for 2022, Conference: C-USA...\n",
      "Fetching data for 2022, Conference: MAC...\n",
      "Fetching data for 2022, Conference: Sun Belt...\n",
      "Fetching data for 2023, Conference: SEC...\n",
      "Fetching data for 2023, Conference: ACC...\n",
      "Fetching data for 2023, Conference: Big Ten...\n",
      "Fetching data for 2023, Conference: Big 12...\n",
      "Fetching data for 2023, Conference: Pac-12...\n",
      "Fetching data for 2023, Conference: AAC...\n",
      "Fetching data for 2023, Conference: MWC...\n",
      "Fetching data for 2023, Conference: C-USA...\n",
      "Fetching data for 2023, Conference: MAC...\n",
      "Fetching data for 2023, Conference: Sun Belt...\n",
      "Fetching data for 2024, Conference: SEC...\n",
      "Fetching data for 2024, Conference: ACC...\n",
      "Fetching data for 2024, Conference: Big Ten...\n",
      "Fetching data for 2024, Conference: Big 12...\n",
      "Fetching data for 2024, Conference: Pac-12...\n",
      "Fetching data for 2024, Conference: AAC...\n",
      "Fetching data for 2024, Conference: MWC...\n",
      "Fetching data for 2024, Conference: C-USA...\n",
      "Fetching data for 2024, Conference: MAC...\n",
      "Fetching data for 2024, Conference: Sun Belt...\n",
      "Fetching data for 2025, Conference: SEC...\n",
      "Fetching data for 2025, Conference: ACC...\n",
      "Fetching data for 2025, Conference: Big Ten...\n",
      "Fetching data for 2025, Conference: Big 12...\n",
      "Fetching data for 2025, Conference: Pac-12...\n",
      "Fetching data for 2025, Conference: AAC...\n",
      "Fetching data for 2025, Conference: MWC...\n",
      "Fetching data for 2025, Conference: C-USA...\n",
      "Fetching data for 2025, Conference: MAC...\n",
      "Fetching data for 2025, Conference: Sun Belt...\n",
      "Data collection complete! Saved to team_box_scores_2015_2025.csv.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# API base URL for team box score statistics\n",
    "team_box_score_url = \"https://api.collegefootballdata.com/games/teams\"\n",
    "\n",
    "# Years to collect data for (2015-2025)\n",
    "years = range(2015, 2026)  # Inclusive of 2025\n",
    "\n",
    "# List of conferences (adjust based on available conferences)\n",
    "conferences = [\"SEC\", \"ACC\", \"Big Ten\", \"Big 12\", \"Pac-12\", \"AAC\", \"MWC\", \"C-USA\", \"MAC\", \"Sun Belt\"]\n",
    "\n",
    "# Authorization Header (replace with your API key)\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer vxEyQMi1J8NLv2HGes5VoTkMZrecMCkXL+8ijS6mBWeobZPm61+nvIwwaXfwxU4N\"  # Replace YOUR_API_KEY with your valid key\n",
    "}\n",
    "\n",
    "# List to store data for all years and conferences\n",
    "all_data = []\n",
    "\n",
    "# Loop through each year and each conference\n",
    "for year in years:\n",
    "    for conference in conferences:\n",
    "        print(f\"Fetching data for {year}, Conference: {conference}...\")\n",
    "        params = {\n",
    "            \"year\": year,\n",
    "            \"conference\": conference,  # Specify the conference\n",
    "            \"classification\": \"fbs\",  # Include all FBS teams\n",
    "            \"seasonType\": \"regular\",  # Regular season data\n",
    "        }\n",
    "        response = requests.get(team_box_score_url, headers=headers, params=params)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            try:\n",
    "                data = response.json()  # Parse JSON response\n",
    "                all_data.extend(data)  # Add data for this year and conference\n",
    "            except ValueError:  # JSONDecodeError\n",
    "                print(f\"Non-JSON response for {year}, Conference: {conference}: {response.text}\")\n",
    "        else:\n",
    "            print(f\"Error fetching data for {year}, Conference: {conference}: {response.status_code}\")\n",
    "            print(response.text)\n",
    "\n",
    "# Convert the aggregated data into a DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Save to a CSV file for future analysis\n",
    "df.to_csv(\"team_box_scores_2015_2025.csv\", index=False)\n",
    "\n",
    "print(\"Data collection complete! Saved to team_box_scores_2015_2025.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21c00177-a88f-48c1-8fdf-e3d95dcf789e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching draft picks data for 2015...\n",
      "Fetching draft picks data for 2016...\n",
      "Fetching draft picks data for 2017...\n",
      "Fetching draft picks data for 2018...\n",
      "Fetching draft picks data for 2019...\n",
      "Fetching draft picks data for 2020...\n",
      "Fetching draft picks data for 2021...\n",
      "Fetching draft picks data for 2022...\n",
      "Fetching draft picks data for 2023...\n",
      "Fetching draft picks data for 2024...\n",
      "Fetching draft picks data for 2025...\n",
      "Draft picks data saved to draft_picks_2015_2025.csv!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Base URLs for APIs\n",
    "draft_picks_url = \"https://api.collegefootballdata.com/draft/picks\"\n",
    "\n",
    "# Authorization Header (replace YOUR_API_KEY)\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer vxEyQMi1J8NLv2HGes5VoTkMZrecMCkXL+8ijS6mBWeobZPm61+nvIwwaXfwxU4N\"  # Replace YOUR_API_KEY with your valid key\n",
    "}\n",
    "\n",
    "#Fetch data from /draft/picks for 2015â€“2025 ---\n",
    "years = range(2015, 2026)  # Inclusive of 2025\n",
    "all_picks_data = []\n",
    "\n",
    "for year in years:\n",
    "    print(f\"Fetching draft picks data for {year}...\")\n",
    "    response = requests.get(draft_picks_url, headers=headers, params={\"year\": year})\n",
    "    if response.status_code == 200:\n",
    "        picks_data = response.json()\n",
    "        all_picks_data.extend(picks_data)\n",
    "    else:\n",
    "        print(f\"Error fetching draft picks for {year}: {response.status_code}\")\n",
    "        print(response.text)\n",
    "\n",
    "picks_df = pd.DataFrame(all_picks_data)\n",
    "picks_df.to_csv(\"draft_picks_2015_2025.csv\", index=False)\n",
    "print(\"Draft picks data saved to draft_picks_2015_2025.csv!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c161be0d-0a26-4f0b-a445-892450bc2dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft Picks:\n",
      "    collegeAthleteId  nflAthleteId  collegeId    collegeTeam collegeConference  \\\n",
      "0          530308.0         46810         52  Florida State               ACC   \n",
      "1          511459.0         46814       2483         Oregon            Pac-12   \n",
      "2         2980100.0         46813         57        Florida               SEC   \n",
      "3          534458.0         46812        333        Alabama               SEC   \n",
      "4          500839.0         46815       2294           Iowa           Big Ten   \n",
      "\n",
      "        nflTeam  year  overall  round  pick              name  \\\n",
      "0     Tampa Bay  2015        1      1     1    Jameis Winston   \n",
      "1     Tennessee  2015        2      1     2    Marcus Mariota   \n",
      "2  Jacksonville  2015        3      1     3  Dante Fowler Jr.   \n",
      "3     Las Vegas  2015        4      1     4      Amari Cooper   \n",
      "4    Washington  2015        5      1     5   Brandon Scherff   \n",
      "\n",
      "           position  height  weight  preDraftRanking  preDraftPositionRanking  \\\n",
      "0       Quarterback    76.0   231.0              1.0                      1.0   \n",
      "1       Quarterback    76.0   222.0              5.0                      2.0   \n",
      "2     Defensive End    75.0   261.0              4.0                      2.0   \n",
      "3     Wide Receiver    73.0   211.0              3.0                      1.0   \n",
      "4  Offensive Tackle    77.0   319.0              6.0                      1.0   \n",
      "\n",
      "   preDraftGrade                                       hometownInfo  \n",
      "0           97.0  {'city': 'Bessemer', 'state': 'AL', 'country':...  \n",
      "1           93.0  {'city': 'Honolulu', 'state': 'HI', 'country':...  \n",
      "2           93.0  {'city': None, 'state': None, 'country': None,...  \n",
      "3           94.0  {'city': 'Miami', 'state': 'FL', 'country': 'U...  \n",
      "4           93.0  {'city': 'Denison', 'state': 'IA', 'country': ...  \n",
      "Draft Picks Columns: Index(['collegeAthleteId', 'nflAthleteId', 'collegeId', 'collegeTeam',\n",
      "       'collegeConference', 'nflTeam', 'year', 'overall', 'round', 'pick',\n",
      "       'name', 'position', 'height', 'weight', 'preDraftRanking',\n",
      "       'preDraftPositionRanking', 'preDraftGrade', 'hometownInfo'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Explore the Individual Data Sets\n",
    "#Start by loading and inspecting each dataset to understand their structure (e.g., columns and unique values):\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Load the datasets\n",
    "draft_picks = pd.read_csv(\"draft_picks_2015_2025.csv\")\n",
    "\n",
    "# Inspect the first few rows of each dataset\n",
    "print(\"Draft Picks:\\n\", draft_picks.head())\n",
    "\n",
    "# Check column names\n",
    "print(\"Draft Picks Columns:\", draft_picks.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e239b349-3d7e-48d5-9ce6-52df411da18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
